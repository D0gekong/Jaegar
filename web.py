import streamlit as st
import yaml
import sqlite3
import pandas as pd
import os
import asyncio
import json
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
from pyvis.network import Network
import streamlit.components.v1 as components

# å¼•å…¥æ‰€æœ‰å·¥å…·
from servers.smart_fofa import (
    step1_check_risk, step2_google_intel_rag, step3_fofa_search,
    step4_tide_fingerprint, step5_port_scan, step6_js_finder,
    step7_trace_real_ip, step8_check_special_routes, step9_generate_report,
    step10_nuclei_scan, step11_hydra_crack, step12_dirsearch_scan, step13_sqlmap_scan,step14_python_interpreter
)

st.set_page_config(page_title="Jaegar AI ç»ˆç«¯", layout="wide", page_icon="ğŸ¦…")
load_dotenv()

API_KEY = os.getenv("API_KEY")
BASE_URL = os.getenv("BASE_URL")
MODEL_NAME = os.getenv("MODEL_NAME")
DB_PATH = os.path.join(os.path.dirname(__file__), "assets.db")

def load_workflow_config():
    yaml_path = os.path.join(os.path.dirname(__file__), "workflows.yaml")
    try:
        with open(yaml_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
            
        # åŠ¨æ€æ‹¼æ¥ System Prompt
        # 1. è§’è‰²å®šä¹‰
        prompt = f"{config['role']['description']} ä½ çš„é£æ ¼æ˜¯ï¼š{config['role']['style']}\n\n"
        
        # 2. å·¥å…·èƒ½åŠ›
        prompt += "ã€å·¥å…·ç®±èƒ½åŠ›è¯´æ˜ã€‘\n"
        for t in config['tools']:
            prompt += f"- {t['name']}: {t['desc']}\n"
            
        # 3. SOP æµç¨‹
        prompt += f"\nã€SOP æ ‡å‡†ä½œä¸šæµç¨‹ã€‘\n{config['workflow']}"
        
        return prompt, config['role']['name']
    except Exception as e:
        st.error(f"åŠ è½½ workflows.yaml å¤±è´¥: {e}")
        # é™çº§æ–¹æ¡ˆ
        return "ä½ æ˜¯ä¸€ä¸ªçº¢é˜Ÿä¸“å®¶...", "Jaegar"

if "client" not in st.session_state:
    st.session_state.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

if "messages" not in st.session_state:
    system_prompt, bot_name = load_workflow_config()
    
    st.session_state.messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": f"ğŸ¦… {bot_name} (SOPé…ç½®ç‰ˆ) å·²å°±ç»ªã€‚è¯·ä¸‹è¾¾æŒ‡ä»¤ã€‚"}
    ]

TOOLS_SCHEMA = [
    {"type": "function", "function": {"name": "step1_check_risk", "description": "é£æ§", "parameters": {"type": "object", "properties": {"domain": {"type": "string"}}, "required": ["domain"]}}},
    {"type": "function", "function": {"name": "step2_google_intel_rag", "description": "æƒ…æŠ¥", "parameters": {"type": "object", "properties": {"domain": {"type": "string"}, "intent": {"type": "string"}}, "required": ["domain"]}}},
    {"type": "function", "function": {"name": "step3_fofa_search", "description": "FOFA", "parameters": {"type": "object", "properties": {"query": {"type": "string"}}, "required": ["query"]}}},
    {"type": "function", "function": {"name": "step4_tide_fingerprint", "description": "æŒ‡çº¹", "parameters": {"type": "object", "properties": {"url": {"type": "string"}}, "required": ["url"]}}},
    {"type": "function", "function": {"name": "step5_port_scan", "description": "ç«¯å£æ‰«æã€‚é»˜è®¤ä½¿ç”¨å¿«é€Ÿæ¨¡å¼(Socket)ï¼Œè‹¥éœ€è¦æœåŠ¡ç‰ˆæœ¬ä¿¡æ¯è¯·ä½¿ç”¨æ·±åº¦æ¨¡å¼(Nmap)", "parameters": {"type": "object", "properties": {"target_ip": {"type": "string"},"mode": {"type": "string", "enum": ["fast", "deep"], "description": "deep: è°ƒç”¨Nmapè¿›è¡ŒæœåŠ¡ç‰ˆæœ¬è¯†åˆ«; fast: ä»…æ£€æµ‹ç«¯å£æ˜¯å¦å¼€æ”¾"}}, "required": ["target_ip"]}}},
    {"type": "function", "function": {"name": "step6_js_finder", "description": "JSæŒ–æ˜", "parameters": {"type": "object", "properties": {"url": {"type": "string"}}, "required": ["url"]}}},
    {"type": "function", "function": {"name": "step7_trace_real_ip", "description": "æº¯æº", "parameters": {"type": "object", "properties": {"url": {"type": "string"}}, "required": ["url"]}}},
    {"type": "function", "function": {"name": "step8_check_special_routes", "description": "è·¯ç”±", "parameters": {"type": "object", "properties": {"url": {"type": "string"}}, "required": ["url"]}}},
    {"type": "function", "function": {"name": "step9_generate_report", "description": "æŠ¥å‘Š", "parameters": {"type": "object", "properties": {}}}},
    {"type": "function", "function": {"name": "step10_nuclei_scan", "description": "Nuclei", "parameters": {"type": "object", "properties": {"url": {"type": "string"}, "tags": {"type": "string"}}, "required": ["url"]}}},
    {"type": "function", "function": {"name": "step11_hydra_crack", "description": "Hydra", "parameters": {"type": "object", "properties": {"target_ip": {"type": "string"}, "service": {"type": "string"}, "port": {"type": "integer"}}, "required": ["target_ip", "service"]}}},
    {"type": "function", "function": {"name": "step12_dirsearch_scan", "description": "Dirsearch", "parameters": {"type": "object", "properties": {"url": {"type": "string"}}, "required": ["url"]}}},
    {"type": "function", "function": {"name": "step13_sqlmap_scan", "description": "SQLMap", "parameters": {"type": "object", "properties": {"url": {"type": "string"}}, "required": ["url"]}}},
    {"type": "function", "function": {"name": "step14_python_interpreter", "description": "ä»£ç è§£é‡Šå™¨", "parameters": {"type": "object", "properties": {"code": {"type": "string"}, "data_context": {"type": "string"}}, "required": ["code"]}}}
]

TOOL_MAP = {
    "step1_check_risk": step1_check_risk,
    "step2_google_intel_rag": step2_google_intel_rag,
    "step3_fofa_search": step3_fofa_search,
    "step4_tide_fingerprint": step4_tide_fingerprint,
    "step5_port_scan": step5_port_scan,
    "step6_js_finder": step6_js_finder,
    "step7_trace_real_ip": step7_trace_real_ip,
    "step8_check_special_routes": step8_check_special_routes,
    "step9_generate_report": step9_generate_report,
    "step10_nuclei_scan": step10_nuclei_scan,
    "step11_hydra_crack": step11_hydra_crack,
    "step12_dirsearch_scan": step12_dirsearch_scan,
    "step13_sqlmap_scan": step13_sqlmap_scan,
    "step14_python_interpreter": step14_python_interpreter
}

def load_data():
    if not os.path.exists(DB_PATH): return pd.DataFrame()
    try:
        conn = sqlite3.connect(DB_PATH)
        df = pd.read_sql_query("SELECT * FROM assets ORDER BY id DESC", conn)
        conn.close()
        return df
    except: return pd.DataFrame()

def draw_topology(df):
    if df.empty: return None
    net = Network(height='300px', width='100%', bgcolor='#0E1117', font_color='white')
    net.force_atlas_2based()
    color_map = {"Subdomain": "#00ff00", "IP": "#ff0000", "Port": "#ffff00", "Fingerprint": "#00ffff", "Vuln": "#ff00ff", "Dir": "#0000ff", "Crack": "#ff0000"}
    for _, row in df.head(50).iterrows():
        try:
            target = str(row['target'])
            atype = str(row['type'])
            info = str(row['info'])
            net.add_node(target, label=target[:15], title=f"[{atype}]\n{info}", color=color_map.get(atype, "#cccccc"), size=15)
        except: pass
    try:
        path = os.path.join(os.path.dirname(__file__), "topology.html")
        net.save_graph(path)
        return path
    except: return None

with st.sidebar:
    st.header("ğŸ“ŠJaegar å®æ—¶æ€åŠ¿")
    if st.button("ğŸ”„ åˆ·æ–°"): st.rerun()
    if st.button("ğŸ§¹ æ¸…é™¤ç¼“å­˜"): 
        st.session_state.messages = []
        st.rerun()
    df = load_data()
    if not df.empty:
        c1, c2 = st.columns(2)
        c1.metric("æ€»èµ„äº§", len(df))
        c2.metric("æ¼æ´/é£é™©", len(df[df['type'].str.contains('Vuln|Crack|Dir', na=False)]))
        html_path = draw_topology(df)
        if html_path:
            with open(html_path, 'r', encoding='utf-8') as f: components.html(f.read(), height=320)
        st.dataframe(df[['target', 'type', 'info']].head(10), hide_index=True, width=300)

st.title("ğŸ›¡ï¸ Jaegar äº¤äº’å¼ä¾¦å¯Ÿç»ˆç«¯")

for msg in st.session_state.messages:
    if isinstance(msg, dict):
        role = msg.get("role")
        content = msg.get("content")
    else:
        role = getattr(msg, "role", None)
        content = getattr(msg, "content", None)
    if role != "system" and content:
        with st.chat_message(role): st.markdown(content)

if prompt := st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        response = st.session_state.client.chat.completions.create(
            model=MODEL_NAME, messages=st.session_state.messages, tools=TOOLS_SCHEMA
        )
        msg = response.choices[0].message
        
        if msg.tool_calls:
            # å­˜å…¥å­—å…¸æ ¼å¼
            st.session_state.messages.append({"role": msg.role, "content": msg.content, "tool_calls": msg.tool_calls})
            for tool_call in msg.tool_calls:
                func_name = tool_call.function.name
                args = json.loads(tool_call.function.arguments)
                with st.status(f"æ‰§è¡Œ: {func_name} ...", expanded=True) as status:
                    st.write(f"å‚æ•°: {args}")
                    if func_name in TOOL_MAP:
                        # å¼‚æ­¥è¿è¡Œå·¥å…·
                        result = asyncio.run(TOOL_MAP[func_name](**args))
                        st.code(str(result)[:500], language="text")
                        
                        # å›ä¼ å·¥å…·ç»“æœ
                        st.session_state.messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": str(result)
                        })
                        status.update(label=f"{func_name} å®Œæˆ!", state="complete", expanded=False)
                    else:
                        # ã€å…³é”®ä¿®å¤ã€‘å³ä½¿æ‰¾ä¸åˆ°å·¥å…·ï¼Œä¹Ÿè¦å›ä¼ ä¸€ä¸ªé”™è¯¯æ¶ˆæ¯ï¼Œé˜²æ­¢ 400
                        err_msg = f"Error: Tool {func_name} not implemented locally."
                        st.error(err_msg)
                        st.session_state.messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": err_msg
                        })
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨è·å–å›ç­”
            final_response = st.session_state.client.chat.completions.create(model=MODEL_NAME, messages=st.session_state.messages)
            ai_reply = final_response.choices[0].message.content
            message_placeholder.markdown(ai_reply)
            st.session_state.messages.append({"role": "assistant", "content": ai_reply})
            st.rerun()
        else:
            ai_reply = msg.content
            message_placeholder.markdown(ai_reply)
            st.session_state.messages.append({"role": "assistant", "content": ai_reply})